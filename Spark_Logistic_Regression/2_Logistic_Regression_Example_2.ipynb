{"nbformat_minor": 4, "cells": [{"source": "# Logistic Regression Example 2\nWe will use the famous titanic dataset for this example.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "from pyspark.sql import SparkSession", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 2, "cell_type": "code", "source": "spark = SparkSession.builder.appName('myproj').getOrCreate()", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 3, "cell_type": "code", "source": "data = spark.read.csv('gs://big-data-class-bucket/titanic.csv',inferSchema=True,header=True)", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 4, "cell_type": "code", "source": "data.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- PassengerId: integer (nullable = true)\n |-- Survived: integer (nullable = true)\n |-- Pclass: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- SibSp: integer (nullable = true)\n |-- Parch: integer (nullable = true)\n |-- Ticket: string (nullable = true)\n |-- Fare: double (nullable = true)\n |-- Cabin: string (nullable = true)\n |-- Embarked: string (nullable = true)\n\n"}], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 5, "cell_type": "code", "source": "data.columns", "outputs": [{"execution_count": 5, "output_type": "execute_result", "data": {"text/plain": "['PassengerId',\n 'Survived',\n 'Pclass',\n 'Name',\n 'Sex',\n 'Age',\n 'SibSp',\n 'Parch',\n 'Ticket',\n 'Fare',\n 'Cabin',\n 'Embarked']"}, "metadata": {}}], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 6, "cell_type": "code", "source": "my_cols = data.select(['Survived',\n 'Pclass',\n 'Sex',\n 'Age',\n 'SibSp',\n 'Parch',\n 'Fare',\n 'Embarked'])", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 7, "cell_type": "code", "source": "my_final_data = my_cols.na.drop()", "outputs": [], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"source": "### Working with Categorical Columns\n\nLet's break this down into multiple steps to make it all clear.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n                                OneHotEncoder,StringIndexer)", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 9, "cell_type": "code", "source": "gender_indexer = StringIndexer(inputCol='Sex',outputCol='SexIndex')\ngender_encoder = OneHotEncoder(inputCol='SexIndex',outputCol='SexVec')", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 10, "cell_type": "code", "source": "embark_indexer = StringIndexer(inputCol='Embarked',outputCol='EmbarkIndex')\nembark_encoder = OneHotEncoder(inputCol='EmbarkIndex',outputCol='EmbarkVec')", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 11, "cell_type": "code", "source": "assembler = VectorAssembler(inputCols=['Pclass',\n 'SexVec',\n 'Age',\n 'SibSp',\n 'Parch',\n 'Fare',\n 'EmbarkVec'],outputCol='features')", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 12, "cell_type": "code", "source": "from pyspark.ml.classification import LogisticRegression", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"source": "## Pipelines ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": "from pyspark.ml import Pipeline", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 14, "cell_type": "code", "source": "log_reg_titanic = LogisticRegression(featuresCol='features',labelCol='Survived')", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 15, "cell_type": "code", "source": "pipeline = Pipeline(stages=[gender_indexer,embark_indexer,\n                           gender_encoder,embark_encoder,\n                           assembler,log_reg_titanic])", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 16, "cell_type": "code", "source": "train_titanic_data, test_titanic_data = my_final_data.randomSplit([0.7,.3])", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 17, "cell_type": "code", "source": "fit_model = pipeline.fit(train_titanic_data)", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 18, "cell_type": "code", "source": "results = fit_model.transform(test_titanic_data)", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 19, "cell_type": "code", "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 20, "cell_type": "code", "source": "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n                                       labelCol='Survived')", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 21, "cell_type": "code", "source": "results.select('Survived','prediction').show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------+----------+\n|Survived|prediction|\n+--------+----------+\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       1.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n|       0|       0.0|\n+--------+----------+\nonly showing top 20 rows\n\n"}], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 22, "cell_type": "code", "source": "AUC = my_eval.evaluate(results)", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 23, "cell_type": "code", "source": "AUC", "outputs": [{"execution_count": 23, "output_type": "execute_result", "data": {"text/plain": "0.798113810741688"}, "metadata": {}}], "metadata": {"jupyter": {"outputs_hidden": false}}}, {"source": "AUC is the area under the [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curve. It is a metric for binary classification.", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pyspark", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}, "anaconda-cloud": {}}}