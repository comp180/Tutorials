{"nbformat_minor": 4, "cells": [{"source": "# Logistic Regression Example 1\n\nLet's see an example of how to run a logistic regression with Python and Spark. This is the official documentation example: https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('logregdoc').getOrCreate()", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 2, "cell_type": "code", "source": "from pyspark.ml.classification import LogisticRegression", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 3, "cell_type": "code", "source": "# Load training data\ntraining = spark.read.format(\"libsvm\").load(\"gs://big-data-class-bucket/sample_libsvm_data.txt\")\n\nlr = LogisticRegression()\n\n# Fit the model\nlrModel = lr.fit(training)\n\ntrainingSummary = lrModel.summary", "outputs": [], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 4, "cell_type": "code", "source": "trainingSummary.predictions.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+--------------------+--------------------+--------------------+----------+\n|label|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+----------+\n|  0.0|(692,[127,128,129...|[19.8534775947479...|[0.99999999761359...|       0.0|\n|  1.0|(692,[158,159,160...|[-20.377398194908...|[1.41321555110997...|       1.0|\n|  1.0|(692,[124,125,126...|[-27.401459284891...|[1.25804865126969...|       1.0|\n|  1.0|(692,[152,153,154...|[-18.862741612668...|[6.42710509170369...|       1.0|\n|  1.0|(692,[151,152,153...|[-20.483011833009...|[1.27157209200630...|       1.0|\n|  0.0|(692,[129,130,131...|[19.8506078990278...|[0.99999999760673...|       0.0|\n|  1.0|(692,[158,159,160...|[-20.337256674834...|[1.47109814695508...|       1.0|\n|  1.0|(692,[99,100,101,...|[-19.595579753418...|[3.08850168102545...|       1.0|\n|  0.0|(692,[154,155,156...|[19.2708803215613...|[0.99999999572670...|       0.0|\n|  0.0|(692,[127,128,129...|[23.6202328360423...|[0.99999999994480...|       0.0|\n|  1.0|(692,[154,155,156...|[-24.385235147660...|[2.56818872776609...|       1.0|\n|  0.0|(692,[153,154,155...|[26.3082522490180...|[0.99999999999624...|       0.0|\n|  0.0|(692,[151,152,153...|[25.8329060318704...|[0.99999999999396...|       0.0|\n|  1.0|(692,[129,130,131...|[-19.794609139087...|[2.53110684529454...|       1.0|\n|  0.0|(692,[154,155,156...|[21.0260440948066...|[0.99999999926123...|       0.0|\n|  1.0|(692,[150,151,152...|[-22.764979942873...|[1.29806018790969...|       1.0|\n|  0.0|(692,[124,125,126...|[21.5049307193955...|[0.99999999954235...|       0.0|\n|  0.0|(692,[152,153,154...|[31.9927184226424...|[0.99999999999998...|       0.0|\n|  1.0|(692,[97,98,99,12...|[-20.521067180413...|[1.22409115616541...|       1.0|\n|  1.0|(692,[124,125,126...|[-22.245377742755...|[2.18250475400404...|       1.0|\n+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"}], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 5, "cell_type": "code", "source": "from pyspark.mllib.evaluation import MulticlassMetrics", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 6, "cell_type": "code", "source": "lrModel.evaluate(training)", "outputs": [{"execution_count": 6, "output_type": "execute_result", "data": {"text/plain": "<pyspark.ml.classification.BinaryLogisticRegressionSummary at 0x7f5990905510>"}, "metadata": {}}], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 7, "cell_type": "code", "source": "# Usually would do this on a separate test set!\npredictionAndLabels = lrModel.evaluate(training)", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 8, "cell_type": "code", "source": "predictionAndLabels.predictions.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+--------------------+--------------------+--------------------+----------+\n|label|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+----------+\n|  0.0|(692,[127,128,129...|[19.8534775947479...|[0.99999999761359...|       0.0|\n|  1.0|(692,[158,159,160...|[-20.377398194908...|[1.41321555110997...|       1.0|\n|  1.0|(692,[124,125,126...|[-27.401459284891...|[1.25804865126969...|       1.0|\n|  1.0|(692,[152,153,154...|[-18.862741612668...|[6.42710509170369...|       1.0|\n|  1.0|(692,[151,152,153...|[-20.483011833009...|[1.27157209200630...|       1.0|\n|  0.0|(692,[129,130,131...|[19.8506078990278...|[0.99999999760673...|       0.0|\n|  1.0|(692,[158,159,160...|[-20.337256674834...|[1.47109814695508...|       1.0|\n|  1.0|(692,[99,100,101,...|[-19.595579753418...|[3.08850168102545...|       1.0|\n|  0.0|(692,[154,155,156...|[19.2708803215613...|[0.99999999572670...|       0.0|\n|  0.0|(692,[127,128,129...|[23.6202328360423...|[0.99999999994480...|       0.0|\n|  1.0|(692,[154,155,156...|[-24.385235147660...|[2.56818872776609...|       1.0|\n|  0.0|(692,[153,154,155...|[26.3082522490180...|[0.99999999999624...|       0.0|\n|  0.0|(692,[151,152,153...|[25.8329060318704...|[0.99999999999396...|       0.0|\n|  1.0|(692,[129,130,131...|[-19.794609139087...|[2.53110684529454...|       1.0|\n|  0.0|(692,[154,155,156...|[21.0260440948066...|[0.99999999926123...|       0.0|\n|  1.0|(692,[150,151,152...|[-22.764979942873...|[1.29806018790969...|       1.0|\n|  0.0|(692,[124,125,126...|[21.5049307193955...|[0.99999999954235...|       0.0|\n|  0.0|(692,[152,153,154...|[31.9927184226424...|[0.99999999999998...|       0.0|\n|  1.0|(692,[97,98,99,12...|[-20.521067180413...|[1.22409115616541...|       1.0|\n|  1.0|(692,[124,125,126...|[-22.245377742755...|[2.18250475400404...|       1.0|\n+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"}], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 9, "cell_type": "code", "source": "predictionAndLabels = predictionAndLabels.predictions.select('label','prediction')", "outputs": [], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 10, "cell_type": "code", "source": "predictionAndLabels.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+----------+\n|label|prediction|\n+-----+----------+\n|  0.0|       0.0|\n|  1.0|       1.0|\n|  1.0|       1.0|\n|  1.0|       1.0|\n|  1.0|       1.0|\n|  0.0|       0.0|\n|  1.0|       1.0|\n|  1.0|       1.0|\n|  0.0|       0.0|\n|  0.0|       0.0|\n|  1.0|       1.0|\n|  0.0|       0.0|\n|  0.0|       0.0|\n|  1.0|       1.0|\n|  0.0|       0.0|\n|  1.0|       1.0|\n|  0.0|       0.0|\n|  0.0|       0.0|\n|  1.0|       1.0|\n|  1.0|       1.0|\n+-----+----------+\nonly showing top 20 rows\n\n"}], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"source": "## Evaluators\n\nEvaluators will be a very important part of our pipline when working with Machine Learning, let's see some basics for Logistic Regression, useful links:\n\nhttps://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.BinaryClassificationEvaluator\n\nhttps://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator", "cell_type": "markdown", "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator", "outputs": [], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 12, "cell_type": "code", "source": "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 13, "cell_type": "code", "source": "# For multiclass\nevaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label',\n                                             metricName='accuracy')", "outputs": [], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}, {"execution_count": 14, "cell_type": "code", "source": "acc = evaluator.evaluate(predictionAndLabels)", "outputs": [], "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}}, {"execution_count": 15, "cell_type": "code", "source": "acc", "outputs": [{"execution_count": 15, "output_type": "execute_result", "data": {"text/plain": "1.0"}, "metadata": {}}], "metadata": {"collapsed": false, "jupyter": {"outputs_hidden": false}}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pyspark", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.14", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}, "anaconda-cloud": {}}}