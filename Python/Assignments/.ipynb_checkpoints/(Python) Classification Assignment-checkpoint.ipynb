{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Automated classification to diagnose cardiac Single Proton Emission Computed Tomography (SPECT) images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be creating a classifier to diagnose a subject's Single Photon Emission Computed Tomography image to determine if he or she is normal or abnormal, in terms of his or her's heart. This is based on the data set present here: <a href= \"https://archive.ics.uci.edu/ml/datasets/SPECT+Heart\">Link </a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 23 attributes recorded from 267 subjects. Note that the presence of a partial diagnosis in the data is indicated with a 1 and the lack of a partial diagnosis is recorded with a 0. If the subject receives an abnormal overall diagnosis, it will be indicated with a 1 and a 0 for a normal overall diagnosis. The following information describes these attributes and the values they can have: \n",
    "\n",
    "<b>Attribute Information:</b>\n",
    "1. OVERALL_DIAGNOSIS: 0,1 (class attribute, binary) \n",
    "2. F1: 0,1 (the partial diagnosis 1, binary) \n",
    "3. F2: 0,1 (the partial diagnosis 2, binary) \n",
    "4. F3: 0,1 (the partial diagnosis 3, binary) \n",
    "5. F4: 0,1 (the partial diagnosis 4, binary) \n",
    "6. F5: 0,1 (the partial diagnosis 5, binary) \n",
    "7. F6: 0,1 (the partial diagnosis 6, binary) \n",
    "8. F7: 0,1 (the partial diagnosis 7, binary) \n",
    "9. F8: 0,1 (the partial diagnosis 8, binary) \n",
    "10. F9: 0,1 (the partial diagnosis 9, binary) \n",
    "11. F10: 0,1 (the partial diagnosis 10, binary) \n",
    "12. F11: 0,1 (the partial diagnosis 11, binary) \n",
    "13. F12: 0,1 (the partial diagnosis 12, binary) \n",
    "14. F13: 0,1 (the partial diagnosis 13, binary) \n",
    "15. F14: 0,1 (the partial diagnosis 14, binary) \n",
    "16. F15: 0,1 (the partial diagnosis 15, binary) \n",
    "17. F16: 0,1 (the partial diagnosis 16, binary) \n",
    "18. F17: 0,1 (the partial diagnosis 17, binary) \n",
    "19. F18: 0,1 (the partial diagnosis 18, binary) \n",
    "20. F19: 0,1 (the partial diagnosis 19, binary) \n",
    "21. F20: 0,1 (the partial diagnosis 20, binary) \n",
    "22. F21: 0,1 (the partial diagnosis 21, binary) \n",
    "23. F22: 0,1 (the partial diagnosis 22, binary) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is divided into:\n",
    "1. Training data (\"SPECT.train\" 80 instances)\n",
    "2. Testing data (\"SPECT.test\" 187 instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this data to build a classifier to diagnose the cardiac SPECT images of the patients in the test data set that has been given to us above. The attribute of \"OVERALL_DIAGNOSIS\" will be used at the training target for the classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the following steps to build your classifier: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open the file 'SPECT.train' in a text editor. \n",
    "\n",
    "Note: the extension is ‘.train’, and even though it is a text file, your operating system may not recognize it as one. One option is to change the extension (to something like ‘.txt’). Another option is to start your text editor and open the file through the editor. In any case doing this will give you a chance to observe the structure of the data while you read the data file details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read the text file in as a dataframe, and then print it to make sure it was read in correctly. \n",
    "\n",
    "This data set does not include column headers. Therefore, when you are reading in the file, you can either make sure the read function is set up to not expect column headers or you can supply your own 23-item lists of strings to serve as column headers. You can use the list below as a starting point. \n",
    "\n",
    "['overall_diagnosis', ‘partial_1’,’partial_2’,’partial_3’,’partial_4’.....] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create an empty training data array, and call it training_data. \n",
    "\n",
    "This should be a array that has 80 rows and 22 columns, and starts filled with all zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Now fill the array with the training data, using the data frame that you read your data into in step #2. Remember to skip the first column when filling the array, since we are using the overall diagnosis as our training point. Also, print the training_data array to make sure it worked. \n",
    "\n",
    "To convert a PANDAS dataframe into a numpy 2D array, we want to use the PANDAS library \"as_matrix\" function (https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.as_matrix.html). \n",
    "\n",
    "When using this function, you can specify the columns you want to import by creating a list with the column names. In this case, we want the columns from 'partial_1' to 'partial_22'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Open the file 'SPECT.test' in a text editor. \n",
    "\n",
    "\n",
    "Note: the extension is ‘.test’, and even though it is a text file, your operating system may not recognize it as one. One option is to change the extension (to something like ‘.txt’). Another option is to start your text editor and open the file through the editor. In any case doing this will give you a chance to observe the structure of the data while you read the data file details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Read the text file in as a dataframe, and then print it to make sure it was read in correctly. \n",
    "\n",
    "This data set does not include column headers. Therefore, when you are reading in the file, you can either make sure the read function is set up to not expect column headers or you can supply your own 23-item lists of strings to serve as column headers, like you did in step #2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create an empty test data array, and call it test_data. \n",
    "\n",
    "This should be an array that is 187 rows and 22 columns, and starts filled with all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Now fill the array with the test data, using the data frame that you read your data into in step #6.  Also, print the test_data array to make sure it worked. \n",
    "\n",
    "To convert a PANDAS dataframe into a numpy 2D array, we want to use the PANDAS library \"as_matrix\" function (https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.as_matrix.html). \n",
    "\n",
    "When using this function, you can specify the columns you want to import by creating a list with the column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train your classifier on training_data and overall_diagnosis (as the training target). Then test the created classifer on the test_data you just retrieved to diagnose each test subject's corresponding SPECT image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9a. Create an overall_diagnosis array and fill it with the values from the first column of the training data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9b. Use the k-nearest neighbors classifier with a k-value = 3. Fit the classifier on the training_data array using the overall_diagnosis array as the training point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9c. Clearly display which of the 187 test subjects will receive an abnormal diagnosis from his or her SPECT image. \n",
    "\n",
    "We can determine the overall accuracy, average recall, and average precious of the predictions by comparing them to the overall diagnosis values from the test data set. Therefore, we want to create an array of the overall diagnosis values from the test data set and then, perform the various computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
